{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2387dfec-ea72-4906-99c0-1f1daa7a8da7",
   "metadata": {},
   "source": [
    "# Gradient Descent Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3fdfb4-09e3-4e4a-8a59-dce34edb9f97",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bbc62c-3bd7-4c56-9fa7-22c31b15c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cecf58a-e044-4cac-9a80-8ded1b59deb9",
   "metadata": {},
   "source": [
    "- We want to minimize this function using the Gradient Descent Method\n",
    "\n",
    "\\begin{equation}\n",
    "f(\\mathbf{x}) = 0.5 \\left( x_1 - 4.5 \\right)^2 + 2.5 \\left( x_2 - 2.3 \\right)^2\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f096d97-8afb-46bf-b467-19ebfbfbc0f9",
   "metadata": {},
   "source": [
    "- The gradient of this function is given by:\\begin{equation}\n",
    "\\nabla f(\\mathbf{x}) = \\begin{bmatrix} \\displaystyle \\frac{\\partial f}{\\partial x_1} \\\\ \\displaystyle\\frac{\\partial f}{\\partial x_2} \\end{bmatrix} = \\begin{bmatrix} x_1 - 4.5 \\\\ 5 \\left( x_2 - 2.3 \\right) \\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63080ee5-dd23-43fc-8795-533e4781e441",
   "metadata": {},
   "source": [
    "- Define two functions. \n",
    "\n",
    "    - One that given a point $\\mathbf{x}$, if computes $f(def f(x):\n",
    "\n",
    "    - One that given a point $\\mathbf{x}$, if computes $\\nabla f(\\mathbf{x})$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d0379c-e14b-4881-b942-653fae470dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    '''Objective function'''\n",
    "# write here your code\n",
    "\n",
    "def df(x):\n",
    "    '''Gradient of the objective function'''\n",
    "# write here your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc21c46-bd64-4f3f-aad1-94099c831c0e",
   "metadata": {},
   "source": [
    "- Compute the minimum of this function using the `scipy` library [SciPy](https://scipy.org/) with the `minimize` method [scipy.optimize.minimize](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html).\n",
    "\n",
    "    - Pass np.zeros(2) as `x0`and use `method='trust-constr'`\n",
    " \n",
    "```python\n",
    "# Expected Output: array([4.5, 2.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f674205-0842-402a-9e2e-3572f2ad4f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# write here your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d102bd1f-b74d-43a7-a0ce-dbcf06a6df09",
   "metadata": {},
   "source": [
    "- Plot the objective function and its minimizer. Rum the following code. Does it agree with the previous result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74381a-acd3-4d9e-a615-df05a0b915ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mesh grid for the function visualization\n",
    "x_vals = np.linspace(-10, 10, 20)\n",
    "y_vals = np.linspace(-10, 10, 20)\n",
    "X_grid, Y_grid = np.meshgrid(x_vals, y_vals)\n",
    "Z_values = f(np.array([X_grid, Y_grid]))\n",
    "\n",
    "# Extract minimizer coordinates\n",
    "opt_x0, opt_x1 = np.meshgrid(result.x[0], result.x[1])\n",
    "opt_z = f(np.stack([opt_x0, opt_x1]))\n",
    "\n",
    "# Initialize figure\n",
    "fig = plt.figure(figsize=(15, 20))\n",
    "\n",
    "# First 3D contour plot\n",
    "ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "ax1.contour3D(X_grid, Y_grid, Z_values, levels=60, cmap='viridis')\n",
    "ax1.scatter(opt_x0, opt_x1, opt_z, color='red', s=80, label='Minimizer')\n",
    "ax1.set_xlabel('$x_0$')\n",
    "ax1.set_ylabel('$x_1$')\n",
    "ax1.set_zlabel('$f(x)$')\n",
    "ax1.view_init(elev=40, azim=20)\n",
    "ax1.legend()\n",
    "\n",
    "# Second 3D contour plot (Top-down view)\n",
    "ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "ax2.contour3D(X_grid, Y_grid, Z_values, levels=60, cmap='viridis')\n",
    "ax2.scatter(opt_x0, opt_x1, opt_z, color='red', s=80, label='Minimizer')\n",
    "ax2.set_xlabel('$x_0$')\n",
    "ax2.set_ylabel('$x_1$')\n",
    "ax2.set_zlabel('$f(x)$')\n",
    "ax2.axes.zaxis.set_ticklabels([])\n",
    "ax2.view_init(elev=90, azim=-90)  # Top-down view\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0776317-bfc1-4c8e-8658-5742578f375f",
   "metadata": {},
   "source": [
    "## Steepest Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50455879-e0d7-4d2d-9041-b565a2bcfbd6",
   "metadata": {},
   "source": [
    "- Given an initial point $\\mathbf{x}_0$, the method follows the update rule:\n",
    "\\begin{equation}\n",
    "        \\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{p}_k,\n",
    "\\end{equation}\n",
    "\n",
    "- $\\mathbf{p}_k$: Search direction.\n",
    "- $\\alpha_k > 0$: Step length.\n",
    "    \n",
    "    \n",
    "For each iteration $k$, the \\textbf{objective} is to compute acceptable $\\mathbf{p}_k$ and $\\alpha_k > 0$ that satisfies certain standard conditions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e332185-64e8-4f24-ba31-8340d2239c88",
   "metadata": {},
   "source": [
    "**The Algorithm**\n",
    "\n",
    "We can now outline the necessary steps for the **steepest descent method**:\n",
    "\n",
    "- Select a starting point $x=x_0$.\n",
    "- Choose a maximum number of iterations $M$.\n",
    "- Define a constant value of $\\alpha$ as input.\n",
    "- Set a tolerance `tol` close to zero to evaluate the gradient as input.\n",
    "- Initialize the step counter $k$.\n",
    "\n",
    "- Iterative Process (repeat in a loop)\n",
    "   1. Compute the next point: $ \\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{p}_k$\n",
    "   2. Evaluate the new gradient:$ \\nabla f(\\mathbf{x})$\n",
    "   4. Increment the step counter: $k=k+1$.\n",
    "   5. Check for stopping conditions:\n",
    "      - If the gradient norm is sufficiently small: $\\nabla f(\\mathbf{x}) < TOL$\n",
    "      - OR if the maximum number of iterations is reached: $k = M$, then exit the loop.\n",
    "    6. **Return** the minimum $\\mathbf{x}^*$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3b3cc8-622d-48b8-a1a5-92da7cf2e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write here your code\n",
    "def steepest_descent(gradient, x0=np.zeros(2), alpha=0.01, max_iter=10000, tolerance=1e-10): \n",
    "    '''\n",
    "    Steepest descent with a fixed step size.\n",
    "\n",
    "    Args:\n",
    "      - gradient: Function computing the gradient of the objective.\n",
    "      - x0: Initial guess for (x_0, x_1) (default: zeros) <numpy.ndarray>.\n",
    "      - alpha: Step size parameter (default: 0.01).\n",
    "      - max_iter: Maximum number of iterations (default: 10,000).\n",
    "      - tolerance: Convergence criterion based on gradient norm (default: 1e-10).\n",
    "\n",
    "    Returns:\n",
    "      - results: <numpy.ndarray> of shape (n_iter, 2) with (x_0, x_1) at each step.\n",
    "      - num_steps: <int> Total number of iterations performed.\n",
    "    '''\n",
    "\n",
    "    # Initialize the array to store iterations\n",
    "    results = np.array([])\n",
    "\n",
    "    # Compute initial gradient\n",
    "    grad_val =  \n",
    "\n",
    "    # Initialize step counter\n",
    "    num_steps =  \n",
    "\n",
    "    # Set initial point\n",
    "    x =  \n",
    "    results = np.append(results, x, axis=0)\n",
    "\n",
    "    # Iterate until convergence or max iterations reached\n",
    "#    while of for / if, as you want\n",
    "\n",
    "        # Move in the direction of the negative gradient\n",
    "        x = \n",
    "\n",
    "        # Store new point\n",
    "        results = np.append(results, x, axis=0)\n",
    "\n",
    "        # Compute new gradient\n",
    "        grad_val = \n",
    "\n",
    "        # Increment step counter\n",
    "\n",
    "\n",
    "    # Reshape results for correct output format\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21090602-0f06-4426-bead-2c590877f4bc",
   "metadata": {},
   "source": [
    "Call this function to minimize $f(\\mathbf{x})$. Use $x_0=(-9, -9)$ and $\\alpha=0.30$\n",
    "\n",
    "```python\n",
    "\n",
    "# Expected Output: \n",
    "# - Optimal solution: [4.5 2.3]\n",
    "# - Total iterations: 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf172f9b-0d69-4c05-a6a8-11ca56f9b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform steepest descent optimization\n",
    "trajectory, num_iterations = steepest_descent(\n",
    "#write here your code\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Display the results\n",
    "print('- Optimal solution:', optimal_point)\n",
    "print('- Total iterations:', num_iterations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0332dcfc-6418-4bec-8302-4b313bf222fa",
   "metadata": {},
   "source": [
    "- Here there is a function to plot the trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27150c97-b2fb-4c6c-9747-2dbfba805cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_optimization_trajectory(trajectory, num_iterations, objective_function):\n",
    "    \"\"\"\n",
    "    Plots the optimization trajectory on a 3D surface plot with the objective function contours.\n",
    "    \n",
    "    Args:\n",
    "        - trajectory: <numpy.ndarray> of size (n_iter, 2) with x_0 and x_1 values at each iteration\n",
    "        - num_iterations: <int> the total number of iterations performed\n",
    "        - objective_function: function to calculate the objective value, takes a 2D array as input\n",
    "    \"\"\"\n",
    "    # Create a meshgrid for X and Y values for the plot\n",
    "    X, Y = np.meshgrid(np.linspace(-10, 10, 50), np.linspace(-10, 10, 50))\n",
    "\n",
    "    # Calculate Z values (the objective function values)\n",
    "    Z = objective_function(np.array([X, Y]))\n",
    "\n",
    "    # Extract coordinates of iterates\n",
    "    X_vals, Y_vals = trajectory[:, 0], trajectory[:, 1]\n",
    "    Z_vals = objective_function(np.array([X_vals, Y_vals]))\n",
    "\n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "    # First 3D plot\n",
    "    ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    ax1.contour3D(X, Y, Z, levels=60, cmap='viridis')\n",
    "    ax1.plot(X_vals, Y_vals, Z_vals, color='red', linewidth=3)\n",
    "    ax1.scatter(trajectory[-1, 0], trajectory[-1, 1], objective_function(trajectory[-1]), marker='o', color='red', s=100)\n",
    "    ax1.set_xlabel('$x_0$')\n",
    "    ax1.set_ylabel('$x_1$')\n",
    "    ax1.set_zlabel('$f(x)$')\n",
    "    ax1.view_init(elev=20, azim=20)\n",
    "\n",
    "    # Second 3D plot\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    ax2.contour3D(X, Y, Z, levels=60, cmap='viridis')\n",
    "    ax2.plot(X_vals, Y_vals, Z_vals, color='red', linewidth=3)\n",
    "    ax2.scatter(trajectory[-1, 0], trajectory[-1, 1], objective_function(trajectory[-1]), marker='o', color='red', s=100)\n",
    "    ax2.set_xlabel('$x_0$')\n",
    "    ax2.set_ylabel('$x_1$')\n",
    "    ax2.set_zlabel('$f(x)$')\n",
    "    ax2.axes.zaxis.set_ticklabels([])\n",
    "    ax2.view_init(elev=90, azim=-90)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76004aff-9247-40e2-a5be-bb46fc16f3bb",
   "metadata": {},
   "source": [
    "- Plot the trajectory by calling this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aa77e5-7dfc-49ab-8a1b-9d2d93f02d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to plot the results\n",
    "plot_optimization_trajectory(trajectory, num_iterations, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47500c5-7bb1-4667-8f58-ebae56dc5e74",
   "metadata": {},
   "source": [
    "- Try new starting points and change the learning rate and analyze what is happening."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd11e04f-0fcd-4cea-8ded-a62a78d333cc",
   "metadata": {},
   "source": [
    "- Include the Armijo condition to calculate the step length."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
