{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2387dfec-ea72-4906-99c0-1f1daa7a8da7",
   "metadata": {},
   "source": [
    "# Gradient Descent Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3fdfb4-09e3-4e4a-8a59-dce34edb9f97",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bbc62c-3bd7-4c56-9fa7-22c31b15c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cecf58a-e044-4cac-9a80-8ded1b59deb9",
   "metadata": {},
   "source": [
    "- We want to minimize this function using the Gradient Descent Method\n",
    "\n",
    "\\begin{equation}\n",
    "f(\\mathbf{x}) = 0.5 \\left( x_1 - 4.5 \\right)^2 + 2.5 \\left( x_2 - 2.3 \\right)^2\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f096d97-8afb-46bf-b467-19ebfbfbc0f9",
   "metadata": {},
   "source": [
    "- The gradient of this function is given by:\\begin{equation}\n",
    "\\nabla f(\\mathbf{x}) = \\begin{bmatrix} \\displaystyle \\frac{\\partial f}{\\partial x_1} \\\\ \\displaystyle\\frac{\\partial f}{\\partial x_2} \\end{bmatrix} = \\begin{bmatrix} x_1 - 4.5 \\\\ 5 \\left( x_2 - 2.3 \\right) \\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63080ee5-dd23-43fc-8795-533e4781e441",
   "metadata": {},
   "source": [
    "- Define two functions. \n",
    "\n",
    "    - One that given a point $\\mathbf{x}$, if computes $f(x)$:\n",
    "\n",
    "    - One that given a point $\\mathbf{x}$, if computes $\\nabla f(\\mathbf{x})$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d0379c-e14b-4881-b942-653fae470dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    '''Objective function'''\n",
    "    return 0.5*(x[0] - 4.5)**2 + 2.5*(x[1] - 2.3)**2\n",
    "\n",
    "def df(x):\n",
    "    '''Gradient of the objective function'''\n",
    "    return np.array([x[0] - 4.5, 5*(x[1] - 2.3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc21c46-bd64-4f3f-aad1-94099c831c0e",
   "metadata": {},
   "source": [
    "- Compute the minimum of this function using the `scipy` library [SciPy](https://scipy.org/) with the `minimize` method [scipy.optimize.minimize](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html).\n",
    "\n",
    "    - Pass np.zeros(2) as `x0`and use `method='trust-constr'`\n",
    " \n",
    "```python\n",
    "# Expected Output: array([4.5, 2.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f674205-0842-402a-9e2e-3572f2ad4f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "result = minimize(\n",
    "    f, np.zeros(2), method='trust-constr', jac=df)\n",
    "\n",
    "result.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d102bd1f-b74d-43a7-a0ce-dbcf06a6df09",
   "metadata": {},
   "source": [
    "- Plot the objective function and its minimizer. Rum the following code. Does it agree with the previous result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74381a-acd3-4d9e-a615-df05a0b915ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mesh grid for the function visualization\n",
    "x_vals = np.linspace(-10, 10, 20)\n",
    "y_vals = np.linspace(-10, 10, 20)\n",
    "X_grid, Y_grid = np.meshgrid(x_vals, y_vals)\n",
    "Z_values = f(np.array([X_grid, Y_grid]))\n",
    "\n",
    "# Extract minimizer coordinates\n",
    "opt_x0, opt_x1 = np.meshgrid(result.x[0], result.x[1])\n",
    "opt_z = f(np.stack([opt_x0, opt_x1]))\n",
    "\n",
    "# Initialize figure\n",
    "fig = plt.figure(figsize=(15, 20))\n",
    "\n",
    "# First 3D contour plot\n",
    "ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "ax1.contour3D(X_grid, Y_grid, Z_values, levels=60, cmap='viridis')\n",
    "ax1.scatter(opt_x0, opt_x1, opt_z, color='red', s=80, label='Minimizer')\n",
    "ax1.set_xlabel('$x_0$')\n",
    "ax1.set_ylabel('$x_1$')\n",
    "ax1.set_zlabel('$f(x)$')\n",
    "ax1.view_init(elev=40, azim=20)\n",
    "ax1.legend()\n",
    "\n",
    "# Second 3D contour plot (Top-down view)\n",
    "ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "ax2.contour3D(X_grid, Y_grid, Z_values, levels=60, cmap='viridis')\n",
    "ax2.scatter(opt_x0, opt_x1, opt_z, color='red', s=80, label='Minimizer')\n",
    "ax2.set_xlabel('$x_0$')\n",
    "ax2.set_ylabel('$x_1$')\n",
    "ax2.set_zlabel('$f(x)$')\n",
    "ax2.axes.zaxis.set_ticklabels([])\n",
    "ax2.view_init(elev=90, azim=-90)  # Top-down view\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0776317-bfc1-4c8e-8658-5742578f375f",
   "metadata": {},
   "source": [
    "## Steepest Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50455879-e0d7-4d2d-9041-b565a2bcfbd6",
   "metadata": {},
   "source": [
    "- Given an initial point $\\mathbf{x}_0$, the method follows the update rule:\n",
    "\\begin{equation}\n",
    "        \\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{p}_k,\n",
    "\\end{equation}\n",
    "\n",
    "- $\\mathbf{p}_k$: Search direction.\n",
    "- $\\alpha_k > 0$: Step length.\n",
    "    \n",
    "    \n",
    "For each iteration $k$, the objective is to compute acceptable $\\mathbf{p}_k$ and $\\alpha_k > 0$ that satisfies certain standard conditions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e332185-64e8-4f24-ba31-8340d2239c88",
   "metadata": {},
   "source": [
    "**The Algorithm**\n",
    "\n",
    "We can now outline the necessary steps for the **steepest descent method**:\n",
    "\n",
    "- Select a starting point $x=x_0$.\n",
    "- Choose a maximum number of iterations $M$.\n",
    "- Set a tolerance `tol` close to zero to evaluate the gradient.\n",
    "- Initialize the step counter $k$.\n",
    "\n",
    "- Iterative Process (repeat in a loop)\n",
    "   1. Compute the next point: $ \\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{p}_k$\n",
    "   2. Evaluate the new gradient:$ \\nabla f(\\mathbf{x})$\n",
    "   4. Increment the step counter: $k=k+1$.\n",
    "   5. Check for stopping conditions:\n",
    "      - If the gradient norm is sufficiently small: $|\\nabla f(\\mathbf{x})| < TOL$\n",
    "      - OR if the maximum number of iterations is reached: $k = M$, then exit the loop.\n",
    "    6. **Return** the minimum $\\mathbf{x}^*$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3b3cc8-622d-48b8-a1a5-92da7cf2e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def steepest_descent(gradient, x0=np.zeros(2), alpha=0.01, max_iter=10000, tolerance=1e-10): \n",
    "    '''\n",
    "    Steepest descent with a fixed step size.\n",
    "\n",
    "    Args:\n",
    "      - gradient: Function computing the gradient of the objective.\n",
    "      - x0: Initial guess for (x_0, x_1) (default: zeros) <numpy.ndarray>.\n",
    "      - alpha: Step size parameter (default: 0.01).\n",
    "      - max_iter: Maximum number of iterations (default: 10,000).\n",
    "      - tolerance: Convergence criterion based on gradient norm (default: 1e-10).\n",
    "\n",
    "    Returns:\n",
    "      - results: <numpy.ndarray> of shape (n_iter, 2) with (x_0, x_1) at each step.\n",
    "      - num_steps: <int> Total number of iterations performed.\n",
    "    '''\n",
    "\n",
    "    # Initialize the array to store iterations\n",
    "    results = np.array([])\n",
    "\n",
    "    # Compute initial gradient\n",
    "    grad_val = gradient(x0)\n",
    "\n",
    "    # Initialize step counter\n",
    "    num_iterations = 0\n",
    "\n",
    "    # Set initial point\n",
    "    x = x0\n",
    "    results = np.append(results, x, axis=0)\n",
    "\n",
    "    # Iterate until convergence or max iterations reached\n",
    "    while any(abs(grad_val) > tolerance) and num_iterations < max_iter:\n",
    "\n",
    "        # Move in the direction of the negative gradient\n",
    "        x = x - alpha * grad_val\n",
    "\n",
    "        # Store new point\n",
    "        results = np.append(results, x, axis=0)\n",
    "\n",
    "        # Compute new gradient\n",
    "        grad_val = gradient(x)\n",
    "\n",
    "        # Increment step counter\n",
    "        num_iterations += 1\n",
    "\n",
    "    # Reshape results for correct output format\n",
    "    return results.reshape(-1, 2), num_iterations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21090602-0f06-4426-bead-2c590877f4bc",
   "metadata": {},
   "source": [
    "Call this function to minimize $f(\\mathbf{x})$\n",
    "\n",
    "```python\n",
    "\n",
    "# Expected Output: \n",
    "# Optimal solution: [4.5 2.3]\n",
    "# Total iterations: 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf172f9b-0d69-4c05-a6a8-11ca56f9b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform steepest descent optimization\n",
    "trajectory, num_iterations = steepest_descent(\n",
    "    df, x0=np.array([-9, -9]), alpha=0.30\n",
    ")\n",
    "\n",
    "# Extract the final minimizer\n",
    "optimal_point = trajectory[-1].round(1)\n",
    "\n",
    "# Display the results\n",
    "print('- Optimal solution:', optimal_point)\n",
    "print('- Total iterations:', num_iterations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0332dcfc-6418-4bec-8302-4b313bf222fa",
   "metadata": {},
   "source": [
    "- Here there is a function to plot the trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27150c97-b2fb-4c6c-9747-2dbfba805cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_optimization_trajectory(trajectory, num_iterations, objective_function):\n",
    "    \"\"\"\n",
    "    Plots the optimization trajectory on a 3D surface plot with the objective function contours.\n",
    "    \n",
    "    Args:\n",
    "        - trajectory: <numpy.ndarray> of size (n_iter, 2) with x_0 and x_1 values at each iteration\n",
    "        - num_iterations: <int> the total number of iterations performed\n",
    "        - objective_function: function to calculate the objective value, takes a 2D array as input\n",
    "    \"\"\"\n",
    "    # Create a meshgrid for X and Y values for the plot\n",
    "    X, Y = np.meshgrid(np.linspace(-10, 10, 50), np.linspace(-10, 10, 50))\n",
    "\n",
    "    # Calculate Z values (the objective function values)\n",
    "    Z = objective_function(np.array([X, Y]))\n",
    "\n",
    "    # Extract coordinates of iterates\n",
    "    X_vals, Y_vals = trajectory[:, 0], trajectory[:, 1]\n",
    "    Z_vals = objective_function(np.array([X_vals, Y_vals]))\n",
    "\n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "    # First 3D plot\n",
    "    ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    ax1.contour3D(X, Y, Z, levels=60, cmap='viridis')\n",
    "    ax1.plot(X_vals, Y_vals, Z_vals, color='red', linewidth=3)\n",
    "    ax1.scatter(trajectory[-1, 0], trajectory[-1, 1], objective_function(trajectory[-1]), marker='o', color='red', s=100)\n",
    "    ax1.set_xlabel('$x_0$')\n",
    "    ax1.set_ylabel('$x_1$')\n",
    "    ax1.set_zlabel('$f(x)$')\n",
    "    ax1.view_init(elev=20, azim=20)\n",
    "\n",
    "    # Second 3D plot\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    ax2.contour3D(X, Y, Z, levels=60, cmap='viridis')\n",
    "    ax2.plot(X_vals, Y_vals, Z_vals, color='red', linewidth=3)\n",
    "    ax2.scatter(trajectory[-1, 0], trajectory[-1, 1], objective_function(trajectory[-1]), marker='o', color='red', s=100)\n",
    "    ax2.set_xlabel('$x_0$')\n",
    "    ax2.set_ylabel('$x_1$')\n",
    "    ax2.set_zlabel('$f(x)$')\n",
    "    ax2.axes.zaxis.set_ticklabels([])\n",
    "    ax2.view_init(elev=90, azim=-90)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76004aff-9247-40e2-a5be-bb46fc16f3bb",
   "metadata": {},
   "source": [
    "- Plot the trajectory by calling this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aa77e5-7dfc-49ab-8a1b-9d2d93f02d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to plot the results\n",
    "plot_optimization_trajectory(trajectory, num_iterations, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47500c5-7bb1-4667-8f58-ebae56dc5e74",
   "metadata": {},
   "source": [
    "- Try these values for the learning rate [0.01, 0.25, 0.3, 0.35, 0.4] and analyze what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a58a95c-4729-428e-8e01-18e3bce94280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc21f72-5cd6-47e1-baf5-611e8a5fe17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5a701b-5753-4311-ba39-136e07f17ba8",
   "metadata": {},
   "source": [
    "- Implement **Armijo Condition** to select the step length.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "  f(\\mathbf{x}_{k+1}) \\leq f(\\mathbf{x}_k) + c_1 \\alpha_k \\nabla f(\\mathbf{x}_k)^T \\mathbf{p}_k, \\qquad 0 < c_1 < 1.\n",
    "    \\end{equation}\n",
    "   Ensures that the objective function decreases sufficiently along the direction $\\mathbf{p}_k$.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "  0. For the Gradient Descent $\\mathbf{p}=-\\nabla f(\\mathbf{x})$\n",
    "  2. Before updating the value of $\\mathbf{x}$, define an initial guess of $\\alpha_0=1$.\n",
    "  3. Half this value until the Armijo condition is met.\n",
    "  4. Once the Armijo condition is met, use this $\\alpha$ to update $\\mathbf{x}$.\n",
    "\n",
    "\n",
    "The name of this procedure is called **backtracking line search**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481a8548-5d65-40d9-a5eb-902cd17b0da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linesearcharmijo(fun, xk, pk, gfk, alpha0, rho=0.5, c1=1e-4):\n",
    "    '''\n",
    "    Minimize over alpha, the function f(xₖ + αpₖ).\n",
    "    α > 0 is assumed to be a descent direction.\n",
    "    \n",
    "    Parameters\n",
    "    --------------------\n",
    "    fun: callable\n",
    "        Function to be minimized.\n",
    "    xk : array\n",
    "        Current point.\n",
    "    pk : array\n",
    "        Search direction.\n",
    "    gfk : array\n",
    "        Gradient of f at point xk.\n",
    "    alpha0 : scalar\n",
    "        Value of alpha at the start of the optimization.\n",
    "    rho : float, optional\n",
    "        Value of alpha shrinkage factor.\n",
    "    c1 : float, optional\n",
    "        Value to control stopping criterion.\n",
    "    \n",
    "    Returns\n",
    "    --------------------\n",
    "    alpha0 : scalar\n",
    "        Value of alpha at the end of the optimization.\n",
    "    phi : float\n",
    "        Value of f at the new point x_{k+1}.\n",
    "    '''\n",
    "\n",
    "    # write your code here:\n",
    "    \n",
    "    return alpha0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdd13c7-a5cd-48a4-8970-564f5d335580",
   "metadata": {},
   "source": [
    "- Include the line search in the gradient descent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d46948-02e2-4641-aa6b-9e22f7290cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def steepest_descent_ls(fun, gradient, x0=np.zeros(2), alpha=1, max_iter=10000, tolerance=1e-10):  \n",
    "    '''\n",
    "    Steepest descent optimization using an adaptive step size (Armijo condition).\n",
    "\n",
    "    Args:\n",
    "      - fun : Callable Function to be minimized.\n",
    "      - gradient: Callable function computing the gradient of the objective function.\n",
    "      - x0: Initial guess for (x_0, x_1) (default: zeros) <numpy.ndarray>.\n",
    "      - alpha: initial step_lengt\n",
    "      - max_iter: Maximum number of iterations allowed (default: 10,000).\n",
    "      - tolerance: Convergence criterion based on gradient norm (default: 1e-10).\n",
    "\n",
    "    Returns:\n",
    "      - f_val: Value of the function in the minimum\n",
    "      - results: <numpy.ndarray> of shape (n_iter, 2) storing (x_0, x_1) at each step.\n",
    "      - num_iterations: <int> Total number of iterations performed.\n",
    "    '''\n",
    "\n",
    "    # Initialize storage for the results\n",
    "    results = np.array([])\n",
    "\n",
    "    # Initialize iteration counter\n",
    "    num_iterations = 0\n",
    "    \n",
    "    # Set the initial point and the initial gradient\n",
    "    xk = x0\n",
    "    grad_val_k = gradient(x0)\n",
    "    \n",
    "    results = np.append(results, xk, axis=0)\n",
    "\n",
    "    # Iterate until convergence or reaching the iteration limit\n",
    "    while any(abs(grad_val_k) > tolerance) and num_iterations < max_iter:\n",
    "\n",
    "        # determine descending direction\n",
    "\n",
    "        \n",
    "        # Compute step size using Armijo condition (adaptive step size)\n",
    "\n",
    "        \n",
    "        # Update current position by moving along the negative gradient\n",
    "\n",
    "        \n",
    "        # Store the new point in the results\n",
    "\n",
    "        \n",
    "        # Compute the new gradient\n",
    "\n",
    "        \n",
    "        # Increment iteration counter\n",
    "\n",
    "        \n",
    "    # Found minimizer\n",
    "\n",
    "\n",
    "        \n",
    "    # Print results\n",
    "    print('- Function minima:', f_val)\n",
    "    print('- Final point:', xk)\n",
    "    print('- N° steps:  {}'.format(num_iterations))\n",
    "\n",
    "    # Reshape and return results\n",
    "    return f_val, results.reshape(-1, 2), num_iterations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ad9aca-9450-435c-9603-1e90e1e0defc",
   "metadata": {},
   "source": [
    "- Compute the minimum of $f(\\mathbf{x})$ for different starting points and compare the results with the problem without the line search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb7147e-a28c-48ad-8f72-ba4c855b3e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steepest descent with line search for f\n",
    "\n",
    "# Possible code, use your own code to call the function you have defined\n",
    "\n",
    "#minima, points, iters = steepest_descent_ls(\n",
    "#  f, df, x0 = np.array([-9, -9]), tolerance=1e-6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c60789b-27fc-4043-8efd-666679186148",
   "metadata": {},
   "source": [
    "- Repeat the process for the Ackley function:\n",
    "\n",
    "\\begin{equation}\n",
    "f(x) = -20 \\exp\\left(-0.2 \\sqrt{\\frac{x_1^2 + x_2^2}{2}}\\right) - \\exp\\left(\\frac{1}{2} \\left( \\cos(2 \\pi x_1) + \\cos(2 \\pi x_2) \\right)\\right) + e + 20\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3eb3cf-38bc-42fc-86d4-c0b2f2279696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ackley(x):\n",
    "    \"\"\"\n",
    "    Ackley function for a 2D input.\n",
    "\n",
    "    Args:\n",
    "        x (numpy.ndarray): Input vector of shape (2,)\n",
    "\n",
    "    Returns:\n",
    "        float: Function value at x.\n",
    "    \"\"\"\n",
    "    term1 = -20 * np.exp(-0.2 * np.sqrt(0.5 * (x[0]**2 + x[1]**2)))\n",
    "    term2 = -np.exp(0.5 * (np.cos(2 * np.pi * x[0]) + np.cos(2 * np.pi * x[1])))\n",
    "    return term1 + term2 + np.e + 20\n",
    "\n",
    "def ackley_gradient(x):\n",
    "    \"\"\"\n",
    "    Gradient of the Ackley function for a 2D input.\n",
    "\n",
    "    Args:\n",
    "        x (numpy.ndarray): Input vector of shape (2,)\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Gradient vector of shape (2,)\n",
    "    \"\"\"\n",
    "    term1_x1 = (20 * x[0]) / np.sqrt(0.5 * (x[0]**2 + x[1]**2)) * np.exp(-0.2 * np.sqrt(0.5 * (x[0]**2 + x[1]**2)))\n",
    "    term1_x2 = (20 * x[1]) / np.sqrt(0.5 * (x[0]**2 + x[1]**2)) * np.exp(-0.2 * np.sqrt(0.5 * (x[0]**2 + x[1]**2)))\n",
    "    \n",
    "    term2_x1 = 2 * np.pi * np.sin(2 * np.pi * x[0]) * np.exp(0.5 * (np.cos(2 * np.pi * x[0]) + np.cos(2 * np.pi * x[1])))\n",
    "    term2_x2 = 2 * np.pi * np.sin(2 * np.pi * x[1]) * np.exp(0.5 * (np.cos(2 * np.pi * x[0]) + np.cos(2 * np.pi * x[1])))\n",
    "\n",
    "    grad_x1 = term1_x1 + term2_x1\n",
    "    grad_x2 = term1_x2 + term2_x2\n",
    "    \n",
    "    return np.array([grad_x1, grad_x2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcae56d-e63c-44fa-aef3-03f8923936c5",
   "metadata": {},
   "source": [
    "Plot the shape of the function evaluating the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d5ec3a-dfb1-4d2b-9e03-3625453927c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product  # Import the product function from itertools\n",
    "\n",
    "# Define the Griewank function (make sure it's defined or replace with the correct one)\n",
    "#def Griewank_plot(x):\n",
    "    # Example implementation of Griewank function\n",
    "#    return 1 + (1/4000) * (x[0]**2 + x[1]**2) - np.cos(x[0]) * np.cos(x[1] / np.sqrt(2))\n",
    "\n",
    "# Generate grid\n",
    "x = np.arange(-5, 5, 0.025)\n",
    "y = np.arange(-5, 5, 0.025)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = np.zeros(X.shape)\n",
    "\n",
    "# Iterate through the grid to compute Z values using the Griewank function\n",
    "mesh_size = range(len(X))\n",
    "for i, j in product(mesh_size, mesh_size):\n",
    "    x_coor = X[i][j]\n",
    "    y_coor = Y[i][j]\n",
    "    Z[i][j] = ackley(np.array([x_coor, y_coor]))\n",
    "\n",
    "# Plot the surface\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')  # Use add_subplot with 'projection' argument\n",
    "ax.set_title('2D Ackley Function')\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')\n",
    "ax.set_zlabel('$f(x_1, x_2)$')\n",
    "ax.plot_surface(X, Y, Z, cmap='viridis')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590bd5ed-8c9f-4117-b3d5-431cbe60a682",
   "metadata": {},
   "source": [
    "- Use the following function to represent the results in the next examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821df9bf-9b34-40f1-b2cc-1e9245730e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_optimization_trajectory_wider(trajectory, num_iterations, objective_function):\n",
    "    \"\"\"\n",
    "    Plots the optimization trajectory on a 3D surface plot with the objective function contours.\n",
    "    \n",
    "    Args:\n",
    "        - trajectory: <numpy.ndarray> of size (n_iter, 2) with x_0 and x_1 values at each iteration\n",
    "        - num_iterations: <int> the total number of iterations performed\n",
    "        - objective_function: function to calculate the objective value, takes a 2D array as input\n",
    "    \"\"\"\n",
    "    # Create a meshgrid for X and Y values for the plot\n",
    "    X, Y = np.meshgrid(np.linspace(-10, 10, 50), np.linspace(-10, 10, 50))\n",
    "\n",
    "    # Calculate Z values (the objective function values)\n",
    "    Z = objective_function(np.array([X, Y]))\n",
    "\n",
    "    # Extract coordinates of iterates\n",
    "    X_vals, Y_vals = trajectory[:, 0], trajectory[:, 1]\n",
    "    Z_vals = objective_function(np.array([X_vals, Y_vals]))\n",
    "\n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "    # First 3D plot (with surface and trajectory)\n",
    "    ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    ax1.contour3D(X, Y, Z, levels=60, cmap='viridis')\n",
    "    ax1.plot(X_vals, Y_vals, Z_vals, color='red', linewidth=3)\n",
    "    ax1.scatter(trajectory[-1, 0], trajectory[-1, 1], objective_function(trajectory[-1]), marker='o', color='red', s=100)\n",
    "    ax1.set_xlabel('$x_0$')\n",
    "    ax1.set_ylabel('$x_1$')\n",
    "    ax1.set_zlabel('$f(x)$')\n",
    "    ax1.view_init(elev=20, azim=20)\n",
    "\n",
    "    # Second 3D plot (contours and trajectory)\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    \n",
    "    # Reduce the contour levels to make the plot clearer\n",
    "    ax2.contour(X, Y, Z, levels=np.linspace(Z.min(), Z.max(), 10), cmap='viridis')  # Sparse contour lines\n",
    "    ax2.plot(X_vals, Y_vals, Z_vals, color='red', linewidth=3)  # Plot trajectory on contours\n",
    "    ax2.scatter(trajectory[-1, 0], trajectory[-1, 1], objective_function(trajectory[-1]), marker='o', color='red', s=100)\n",
    "    ax2.set_xlabel('$x_0$')\n",
    "    ax2.set_ylabel('$x_1$')\n",
    "    ax2.axes.zaxis.set_ticklabels([])  # Remove z axis ticks\n",
    "    ax2.view_init(elev=90, azim=-90)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a099714-6495-4c7f-9c9f-452802ea067c",
   "metadata": {},
   "source": [
    "- Compute the minima for different starting points and learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02950dd2-efcf-44ec-a55f-834f31ea5445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de59c46-458c-4e2f-bbb5-d9f214c5f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_trajectory_wider(points, iters, ackley)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de8d656-baaf-48f7-a8e9-998ac597b6e4",
   "metadata": {},
   "source": [
    "- Repeat the process for the Griewank function:\n",
    "\n",
    "\\begin{equation}\n",
    "    f(x) = 1 + \\frac{1}{4000} \\left( x_1^2 + x_2^2 \\right) - \\prod_{i=1}^{2} \\cos\\left( \\frac{x_i}{\\sqrt{i}} \\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3c5b9d-b777-4f56-a16c-0d56446e8368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Griewank function (2D)\n",
    "def griewank(x):\n",
    "    x1, x2 = x[0], x[1]\n",
    "    term1 = (x1**2 + x2**2) / 4000\n",
    "    term2 = np.cos(x1 / np.sqrt(1)) * np.cos(x2 / np.sqrt(2))\n",
    "    return 1 + term1 - term2\n",
    "\n",
    "# Gradient of the Griewank function (2D)\n",
    "def griewank_gradient(x):\n",
    "    x1, x2 = x[0], x[1]\n",
    "    \n",
    "    # Derivative with respect to x1\n",
    "    df_dx1 = x1 / 2000 + np.sin(x1 / np.sqrt(1)) / np.sqrt(1)\n",
    "    \n",
    "    # Derivative with respect to x2\n",
    "    df_dx2 = x2 / 2000 + np.sin(x2 / np.sqrt(2)) / np.sqrt(2)\n",
    "    \n",
    "    return np.array([df_dx1, df_dx2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f860684-2605-49ba-a425-42c861ba240a",
   "metadata": {},
   "source": [
    "Plot the shape of the function evaluating the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fdca36-5821-47c6-b38f-3733d38320b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import product  # Import the product function from itertools\n",
    "\n",
    "# Define the Griewank function (make sure it's defined or replace with the correct one)\n",
    "#def Griewank_plot(x):\n",
    "    # Example implementation of Griewank function\n",
    "#    return 1 + (1/4000) * (x[0]**2 + x[1]**2) - np.cos(x[0]) * np.cos(x[1] / np.sqrt(2))\n",
    "\n",
    "# Generate grid\n",
    "x = np.arange(-5, 5, 0.025)\n",
    "y = np.arange(-5, 5, 0.025)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = np.zeros(X.shape)\n",
    "\n",
    "# Iterate through the grid to compute Z values using the Griewank function\n",
    "mesh_size = range(len(X))\n",
    "for i, j in product(mesh_size, mesh_size):\n",
    "    x_coor = X[i][j]\n",
    "    y_coor = Y[i][j]\n",
    "    Z[i][j] = griewank(np.array([x_coor, y_coor]))\n",
    "\n",
    "# Plot the surface\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')  # Use add_subplot with 'projection' argument\n",
    "ax.set_title('2D Griewank Function')\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')\n",
    "ax.set_zlabel('$f(x_1, x_2)$')\n",
    "ax.plot_surface(X, Y, Z, cmap='viridis')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ee77d3-28eb-473f-833b-15154fc5f767",
   "metadata": {},
   "source": [
    "- Compute the minima for different starting points and learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851c4dfc-b043-4934-a892-19903759553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4074a4d-85a3-404e-af59-622438e868f3",
   "metadata": {},
   "source": [
    "- Plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd40a9-5573-420b-8269-9bffd2d051d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_trajectory_wider(xpoints, xiters, griewank)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
