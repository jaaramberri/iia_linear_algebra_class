{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4bb49a-5ec6-462c-bb9d-511c37281f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from random import randint\n",
    "plt.style.use('ggplot')\n",
    "from plotting_functions import plot_single_run, pretty_plot_gs\n",
    "# initialize the random seed \n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45936e0-8ab7-42f8-bab0-82054dab89be",
   "metadata": {},
   "source": [
    "## Local Greedy Search\n",
    "The problem is to use local search to find a minimum of a Cost Function $\\min cost(s)$ where $s = \\{s_1, \\ldots, s_m\\}$ where $s$ is a vector whose components can be integer, continuous or both. All heuristic algorithms have three components:\n",
    "1. Initial Solution\n",
    "2. Neighborhood\n",
    "3. Improvement algorithm\n",
    "\n",
    "For the local greedy search:\n",
    "1. Initial solution: randomly pick a $s_{curr}$\n",
    "2. Neighborhood: search the $cost(s)$ function $\\forall s\\in \\{s_{curr}\\pm d\\}$ where $d$ is the range\n",
    "3. Improvement algorithm: Pick the new solution in the neighbourhood that has the best objective function to be $s_{curr}$ in the next iteration\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- **Overview of Search Algorithms**  \n",
    "\n",
    "The following four search algorithms differ in how they update the current solution during the optimization process.  \n",
    "\n",
    " 1. **Random Walk** (RW)  \n",
    "In this approach, the next value of $s$ is randomly selected from the neighboring values of the current solution, $s_{\\text{current}}$.  \n",
    "Throughout the process, we keep track of the best solution found so far, $s_{\\text{best}}$, along with its corresponding function value, $\\cos(s_{\\text{best}})$.  \n",
    "\n",
    " 2. **Random Sampling** (RS)  \n",
    "Unlike the random walk, this method selects the next value of $s$ randomly from *all* possible values, rather than just the neighbors of $s_{\\text{current}}$.  \n",
    "As in RW, we continuously update $s_{\\text{best}}$ and store $\\cos(s_{\\text{best}})$.  \n",
    "\n",
    " 3. **Greedy Deterministic** (GD)  \n",
    "In this method, we always choose the best available neighbor of $s_{\\text{current}}$, ensuring a deterministic improvement at each step.  \n",
    "\n",
    " 4. **Greedy Stochastic** (GS)  \n",
    "The next value of $s$ is randomly selected from the neighbors of the best current solution $s_{\\text{best}}$.  \n",
    "Unlike the deterministic approach, this allows for some exploration while still favoring local improvement.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02446e42-f10a-4ddc-bf97-83013f34adac",
   "metadata": {},
   "source": [
    "**Step 1**: Define the Cost Function.\n",
    "\n",
    "For this example the **cost function** is given by:\n",
    "  \\begin{equation}\n",
    "    f(s)= (400-(s-21)^2)\\cdot \\sin(s\\pi/6)\n",
    "\\end{equation}\n",
    "The constraint on $s: s\\in\\mathbb{N}, 0\\leq s\\leq 500$.\n",
    "The **neighbourhood function** that is implements below for step 2 considers $\\forall s, s.t. max(s_{current}-25, 0)\\leq s \\leq \\min(s_{current}+25, 500)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b993d0f4-84b1-4801-8b77-23eeb4268d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(s):\n",
    "    ''' returns the evaluation of the cost function\n",
    "    on a numpy array of imputs\n",
    "    '''\n",
    "    return (400 - (s-21)**2)* np.sin(s*math.pi/6)\n",
    "\n",
    "x = np.arange(0,500, 1)\n",
    "y = cost(x)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1dc1b8-4ec1-4e99-ba1a-d1c50992847b",
   "metadata": {},
   "source": [
    "- Define what it is considered as a **neighbor** in a deterministic way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aab2090-8997-4e66-b915-496fcc97f8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbors(s, min_s = 0, max_s = 500, d = 25):\n",
    "    # Create a range of values from (s - d) to (s + d), but limit the range \n",
    "    # within [min_s, max_s] to avoid going outside the boundaries.\n",
    "    neigh = np.arange(max(s-d, min_s), min(s+d+1, max_s))\n",
    "    \n",
    "    # Return the neighbors, excluding the current point 's' itself\n",
    "    return neigh[neigh != s]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1133ca8c-02dc-4002-94c7-35729fb67f15",
   "metadata": {},
   "source": [
    "- Define what it is considered as a **random neighbor**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c7f49b-535f-4d9c-b4ed-7bcb53ec2965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_neighbor(s, min_s = 0, max_s = 500, d = 25):\n",
    "    # Initialize s_new to the current position, s\n",
    "    s_new = s\n",
    "    \n",
    "    # Repeat the process until s_new is different from s\n",
    "    while(s_new == s):\n",
    "        # Generate a random value within the range [max(s-d, min_s), min(s+d, max_s)]\n",
    "        # The new value is constrained by the boundaries (min_s and max_s) and the distance d.\n",
    "        s_new = randint(max(s-d, min_s), min(s+d, max_s))\n",
    "    \n",
    "    # Return the new neighbor, which is different from the current position s\n",
    "    return s_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45f96f5-441a-46c0-8f4a-c5112552fd44",
   "metadata": {},
   "source": [
    "- Initialize the variables where we will store the information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a986b7-c7a8-4496-8735-633524ea306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first define times=1 because we will compute more times all the optimization processes in a second part of the notebook and for code reusing.\n",
    "times=1\n",
    "maxIter = 201\n",
    "result = {'RW':np.empty((times, maxIter, 5)) , 'RS':np.empty((times, maxIter, 5)), 'GD':np.empty((times, maxIter, 5)), 'GS':np.empty((times, maxIter, 5))}\n",
    "\n",
    "# We define the same initial point:\n",
    "\n",
    "initial_point = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed440fdf-c958-42c1-a28d-d4e11bc0ad26",
   "metadata": {},
   "source": [
    "# Exercise 1: Random Walk\n",
    "\n",
    "The Random Walk algorithm is a basic optimization technique where, starting from an initial solution, the algorithm explores the solution space by randomly selecting neighboring solutions and updating the best solution based on the cost (or objective function) values.\n",
    "\n",
    "- **Objective**\n",
    "Implement the **Random Walk (RW) algorithm** for optimization from scratch. \n",
    "\n",
    "Given a cost function and the definition of neighboring:\n",
    "\n",
    "- **Instructions**\n",
    "\n",
    "- At each iteration, we will perturb the current solution and evaluate its performance. Specifically, we will:\n",
    "\n",
    "  \n",
    "0. Start with an initial solution `sInitial` and evaluate its cost using the given `cost()` function.\n",
    "1. **Generate a new solution**: Use the `random_neighbor(sCurrent)` function to Randomly perturb the current solution and generate a new solution.\n",
    "2. **Evaluate the new solution’s cost**: After obtaining the new solution, calculate its cost using the `cost(sCurrent)` function.\n",
    "3. **Update the best solution**: If the new solution’s cost is better (lower) than the best solution found so far, update the best solution and best cost.\n",
    "4. **Store iteration data**: For each iteration, store the following information in a matrix:\n",
    "   - The iteration number.\n",
    "   - The current solution (`sCurrent`).\n",
    "   - The best solution found so far (`sBest`).\n",
    "   - The cost of the current solution.\n",
    "   - The cost of the best solution.\n",
    "\n",
    "5. **Repeat** steps 1-3 for a specified number of iterations (`maxIter`).\n",
    "\n",
    "Hint: The matrix should be initialized with dimensions of `maxIter` (number of iterations) by 5 (for the 5 pieces of data you want to store).\n",
    "\n",
    "To initialize the matrix, you can use NumPy’s `empty` function to create an empty array. The first row of this matrix will be filled with the initial values of the solution and its corresponding costs.\n",
    "\n",
    "\n",
    "Hints: Here’s how you can implement the loop:\n",
    "\n",
    "```python\n",
    "\n",
    "#Here’s how you can initialize the matrix and fill in the first iteration’s data:\n",
    "\n",
    "matrix = np.empty((maxIter, 5))  # Initialize an empty matrix with 'maxIter' rows and 5 columns\n",
    "matrix[0, :] = [0, sCurrent, sBest, costCurrent, costBest]  # Store the initial values\n",
    "\n",
    "\n",
    "for i in range(1, maxIter):  # Loop through iterations (starting from 1)\n",
    "    sCurrent = random_neighbor(sCurrent)  # Perturb the current solution to get a new solution\n",
    "    costCurrent = cost(sCurrent)  # Calculate the cost of the new solution\n",
    "    \n",
    "    # If the new solution is better than the best solution so far, update the best solution\n",
    "    if costCurrent < costBest:\n",
    "        costBest = costCurrent  # Update the best cost\n",
    "        sBest = sCurrent  # Update the best solution\n",
    "    \n",
    "    # Store the current data (iteration, current solution, best solution, current cost, best cost)\n",
    "    matrix[i, :] = [i, sCurrent, sBest, costCurrent, costBest]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c37c9-8bc6-49f0-bba4-2656a9e9ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Walk (RW) algorithm implementation\n",
    "def RW(sInitial, maxIter, cost_function, print_info=True):\n",
    "    # Initialize the current solution and best solution to the initial solution (sInitial)\n",
    "    sCurrent, sBest = sInitial, sInitial\n",
    "    \n",
    "    # Calculate the cost of the initial solution\n",
    "\n",
    "        \n",
    "    # Set the best cost initially to the cost of the initial solution\n",
    "\n",
    "        \n",
    "    # Create a matrix to store the iteration data (iteration number, current s, best s, current cost, best cost)\n",
    "    matrix = np.empty((maxIter, 5))\n",
    "    \n",
    "    # Store the data of the first iteration (initial values)\n",
    "\n",
    "        \n",
    "    # Loop through the maximum number of iterations\n",
    "    for i in range(1, maxIter):\n",
    "        # Generate a new neighbor solution by perturbing the current solution (random_walk)\n",
    "\n",
    "                \n",
    "        # Calculate the cost of the new solution\n",
    "\n",
    "                \n",
    "        # Check if the new solution is better than the best solution so far\n",
    "        if costCurrent < costBest:\n",
    "            # If yes, update the best cost and best solution\n",
    "\n",
    "            \n",
    "        \n",
    "        # Store the data of the current iteration (iteration number, current solution, best solution, current cost, best cost)\n",
    "\n",
    "        \n",
    "    if print_info:\n",
    "        print(\"Final Iteration:\", int(i))\n",
    "        print(f\"Best Solution Found: {int(sBest)} with Cost: {costBest:.4f}\")\n",
    "        print(f\"Final Current Solution: {int(sCurrent)} with Cost: {costCurrent:.4f}\")\n",
    "\n",
    "    # Return the matrix containing the data of all iterations\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efee2b00-e743-4ee5-9484-f7f8e5b7590e",
   "metadata": {},
   "source": [
    "- Call the optimizer Random Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4f150a-07d0-4bdc-be26-a20efba0fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['RW'][0] = RW(initial_point, maxIter, cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67223a5-707c-4223-a0c5-51ac5bb4fe5e",
   "metadata": {},
   "source": [
    "- Plot the results using `plot_single_run`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdb6399-0bf4-41e2-8bcb-fb23a5ba413e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_single_run(result, 'RW', maxIter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc39be0-51c5-4e02-b206-30eeb4a0bfa2",
   "metadata": {},
   "source": [
    "# Exercise 2: Random Sampling\n",
    "\n",
    "The **Random Sampling (RS) algorithm** is a simple optimization technique where, instead of exploring neighboring solutions (as in **Random Walk**), the algorithm selects **random solutions from the entire search space** at each iteration. The best solution is updated whenever a better one is found.\n",
    "\n",
    "---\n",
    "\n",
    "**Objective**\n",
    "Implement the **Random Sampling (RS) algorithm** for optimization from scratch.\n",
    "\n",
    "Given a cost function, our goal is to implement an algorithm that explores the entire search space **randomly** and keeps track of the best solution found.\n",
    "\n",
    "---\n",
    "\n",
    "**Instructions**\n",
    "At each iteration, the algorithm will randomly sample a solution and evaluate its performance. Specifically, you will:\n",
    "\n",
    "**Steps:**\n",
    "0. **Initialize the algorithm**:\n",
    "   - Start with an **initial solution** `sInitial`.\n",
    "   - Compute its cost using the given `cost_function()`.\n",
    "   - Set this as the **best solution** so far.\n",
    "\n",
    "1. **Generate a new random solution**:\n",
    "   - Instead of perturbing the current solution, choose a **completely random** value from the entire search range (e.g., between `0` and `500`).\n",
    "\n",
    "2. **Evaluate the new solution’s cost**:\n",
    "   - Compute the cost of the new solution using the given `cost_function(sCurrent)`.\n",
    "\n",
    "3. **Update the best solution**:\n",
    "   - If the new solution is better (lower cost) than the best solution found so far, update both the **best solution** and **best cost**.\n",
    "\n",
    "4. **Store iteration data**:\n",
    "   - At each iteration, store the following information in a matrix:\n",
    "     - The **iteration number**.\n",
    "     - The **current solution** (`sCurrent`).\n",
    "     - The **best solution** found so far (`sBest`).\n",
    "     - The **cost of the current solution**.\n",
    "     - The **cost of the best solution**.\n",
    "\n",
    "5. **Repeat** steps 1–4 for a specified number of iterations (`maxIter`).\n",
    "\n",
    "---\n",
    "\n",
    "**Hints:\n",
    "- Instead of calling `random_neighbor(sCurrent)`, use a function that selects a **completely random** value between `0` and `500` (or another specified range).\n",
    "- Use **NumPy’s** `empty` function to initialize a matrix to store the iteration results.\n",
    "- Store the **initial values** in the first row of the matrix before the loop starts.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05e4ca0-493e-4a22-8622-c10fcff314fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RS(sInitial, maxIter, cost_function, search_range=(0, 500), print_info=True):\n",
    "    \"\"\"\n",
    "    Implements the Random Sampling (RS) algorithm for optimization.\n",
    "\n",
    "    Unlike the Random Walk (RW), this method selects the next value of s\n",
    "    randomly from all possible values within the given range, rather than \n",
    "    just the neighbors of the current s.\n",
    "\n",
    "    Parameters:\n",
    "        sInitial (int): Initial value of s.\n",
    "        maxIter (int): Maximum number of iterations.\n",
    "        cost_function (function): The function to evaluate the cost of a given solution.\n",
    "        search_range (tuple): The lower and upper bounds of s (default is (0,500)).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A matrix storing iteration data (iteration number, sCurrent, sBest, costCurrent, costBest).\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the current solution and best solution to the initial value (sInitial)\n",
    "\n",
    "        \n",
    "    # Compute the initial cost\n",
    "\n",
    "        \n",
    "    # Initialize the best cost with the initial cost\n",
    "\n",
    "    \n",
    "    # Create an empty matrix to store iteration results\n",
    "    # Each row will store: [iteration number, sCurrent, sBest, costCurrent, costBest]\n",
    "\n",
    "        \n",
    "    # Store the initial values in the first row\n",
    "\n",
    "    \n",
    "    # Iterate through the optimization process\n",
    "    for i in range(1, maxIter):\n",
    "        # Select a new random solution within the defined search range\n",
    "\n",
    "                \n",
    "        # Compute the cost of the new solution\n",
    "\n",
    "        \n",
    "        # Update the best solution if the new one is better (lower cost)\n",
    "        if costCurrent < costBest:\n",
    "\n",
    "            \n",
    "        \n",
    "        # Store the iteration data\n",
    "\n",
    "        \n",
    "    if print_info:    \n",
    "        print(\"Final Iteration:\", int(i))\n",
    "        print(f\"Best Solution Found: {int(sBest)} with Cost: {costBest:.4f}\")\n",
    "        print(f\"Final Current Solution: {int(sCurrent)} with Cost: {costCurrent:.4f}\")\n",
    "    \n",
    "    # Return the matrix with all recorded data\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d208b5a5-7d86-447c-b442-13969e282327",
   "metadata": {},
   "source": [
    "- Call the optimizer Random Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a14eea-ab36-4e54-812c-b1e442629552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define times=1 because we will compute more times all the optimization processes in a second part of the notebook.\n",
    "result['RS'][0] = RS(initial_point, maxIter, cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dcadc1-9521-489d-81ae-1a4970c414e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_run(result, 'RS', maxIter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc5caed-5fc5-45ce-8cda-73175b09573f",
   "metadata": {},
   "source": [
    "# Exercise 3: Greedy Deterministic\n",
    "\n",
    "The **Greedy Deterministic (GD) algorithm** is an optimization technique that ensures a **deterministic improvement** at each step.  \n",
    "Unlike **Random Walk (RW)**, which selects a neighbor randomly, the **GD algorithm always chooses the best available neighbor**, moving towards a better solution at each iteration.\n",
    "\n",
    "---\n",
    "\n",
    "**Objective**\n",
    "Implement the **Greedy Deterministic (GD) algorithm** for optimization from scratch.\n",
    "\n",
    "Given a cost function, our goal is to implement an algorithm that **always picks the best neighboring solution** to iteratively improve the objective function.\n",
    "\n",
    "---\n",
    "\n",
    "**Instructions**\n",
    "At each iteration, the algorithm evaluates all neighboring solutions and selects the **best one**. Specifically, you will:\n",
    "\n",
    "**Steps:**\n",
    "0. **Initialize the algorithm**:\n",
    "   - Start with an **initial solution** `sInitial`.\n",
    "   - Compute its cost using the given `cost_function()`.\n",
    "   - Set this as the **best solution** so far (`sBest`).\n",
    "\n",
    "1. **Generate neighboring solutions**:\n",
    "   - Use a `neighbors()` function to get all **neighboring solutions** of `sCurrent`.\n",
    "   - The neighbors should be within a step size `d=10` from `sCurrent`.\n",
    "\n",
    "2. **Evaluate the neighbors’ costs**:\n",
    "   - Compute the cost for each neighboring solution using `cost_function()`.\n",
    "   - Identify the **neighbor with the lowest cost**.\n",
    "\n",
    "3. **Move to the best neighbor**:\n",
    "   - If the best neighbor has a **lower cost** than `sCurrent`, update `sCurrent` to this neighbor.\n",
    "   - Otherwise, keep `sCurrent` unchanged.\n",
    "\n",
    "4. **Update the best solution**:\n",
    "   - If `sCurrent` has a lower cost than `sBest`, update `sBest` and its cost.\n",
    "\n",
    "5. **Store iteration data**:\n",
    "   - At each iteration, store the following information in a matrix:\n",
    "     - **Iteration number**.\n",
    "     - **Current solution (`sCurrent`)**.\n",
    "     - **Best solution found so far (`sBest`)**.\n",
    "     - **Cost of the current solution (`costCurrent`)**.\n",
    "     - **Cost of the best solution (`costBest`)**.\n",
    "\n",
    "6. **Repeat** steps 1–5 for a specified number of iterations (`maxIter`).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c53a68c-9183-4898-a98a-1355bf3efefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greedy Deterministic (GD) algorithm implementation\n",
    "def GD(sInitial, maxIter, cost_function, print_info=True):\n",
    "    \"\"\"\n",
    "    Implements the Greedy Deterministic (GD) optimization algorithm.\n",
    "    \n",
    "    This method always selects the best available neighbor of the current solution, ensuring \n",
    "    a deterministic improvement at each step.\n",
    "    \n",
    "    Parameters:\n",
    "        sInitial (int): The initial solution (starting point in the search space).\n",
    "        maxIter (int): The maximum number of iterations to perform.\n",
    "        cost_function (function): A function that calculates the cost of a given solution.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: A matrix containing the iteration data:\n",
    "                    [iteration number, current solution, best solution, current cost, best cost]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the current solution to the initial solution\n",
    "\n",
    "        \n",
    "    # Compute the cost of the initial solution\n",
    "\n",
    "        \n",
    "    # Initialize the best solution and best cost with the initial values\n",
    "\n",
    "    \n",
    "\n",
    "    # Create a matrix to store iteration data: [iteration number, sCurrent, sBest, costCurrent, costBest]\n",
    "\n",
    "        \n",
    "    # Store the initial iteration data\n",
    "\n",
    "    \n",
    "    # Loop through the maximum number of iterations\n",
    "    for i in range(1, maxIter):\n",
    "        # Generate a list of neighboring solutions within a step size of d=10\n",
    "\n",
    "                \n",
    "        # Compute the cost of each neighboring solution\n",
    "\n",
    "                \n",
    "        # Identify the neighbor with the lowest cost\n",
    "\n",
    "                \n",
    "        # If the best neighbor is better than the current solution, move to it\n",
    "        if costCurrent >= cost_neigh[min_idx]:\n",
    "\n",
    "            \n",
    "        \n",
    "        # Update the best solution if the current one is the best seen so far\n",
    "        if costCurrent < costBest:\n",
    "\n",
    "            \n",
    "\n",
    "        # Store the data for this iteration\n",
    "\n",
    "            \n",
    "    if print_info:\n",
    "        print(\"Final Iteration:\", int(i))\n",
    "        print(f\"Best Solution Found: {int(sBest)} with Cost: {costBest:.4f}\")\n",
    "        print(f\"Final Current Solution: {int(sCurrent)} with Cost: {costCurrent:.4f}\")\n",
    "    \n",
    "    # Return the iteration matrix\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08240c10-acc3-469a-bdf2-e826dca1b996",
   "metadata": {},
   "source": [
    "- Call the optimizer Random Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b65609d-eaab-4ba0-89e5-8096858a97df",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['GD'][0] = GD(initial_point, maxIter, cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e863e-1247-47e2-9fe0-b220da6b54fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_run(result, 'GD', maxIter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5fa18b-a8f6-458d-8401-12f768eec00a",
   "metadata": {},
   "source": [
    "# Exercise 4: Greedy Stochastic\n",
    "\n",
    "**Overview**\n",
    "The **Greedy Stochastic (GS) algorithm** is an optimization technique that balances exploration and exploitation. Unlike purely greedy approaches, which always take the best immediate step, **GS selects a random neighbor** of the current best solution, allowing for some exploration while still favoring improvement.\n",
    "\n",
    "**Objective**\n",
    "Your task is to **implement the Greedy Stochastic (GS) algorithm from scratch** to optimize a given cost function.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "Follow these steps to implement the **Greedy Stochastic (GS) algorithm**:\n",
    "\n",
    "**Step 1: Initialization**\n",
    "- Start with an **initial solution** `s_initial`.\n",
    "- Compute its **cost** using the provided function `cost(s_initial)`.\n",
    "- Set this as both the **current solution** and the **best solution**.\n",
    "\n",
    "**Step 2: Prepare Data Storage**\n",
    "- You need to track the **iteration number, current solution, best solution, current cost, and best cost**.\n",
    "- Create a **NumPy matrix** to store these values across iterations.\n",
    "- Store the **initial values** in the first row of the matrix.\n",
    "\n",
    "**Step 3: Iterative Improvement**\n",
    "For each iteration:\n",
    "\n",
    "1. **Select a new solution**  \n",
    "   - Instead of picking any random neighbor, select a **random neighbor of the best solution so far**.  \n",
    "   - Use the function `random_neighbor(sBest)`.\n",
    "\n",
    "2. **Evaluate the new solution**  \n",
    "   - Compute its cost using `cost(sCurrent)`.\n",
    "\n",
    "3. **Update the best solution**  \n",
    "   - If the new solution is **better (lower cost)** than the best solution so far, update both:\n",
    "     - `sBest` (best solution)\n",
    "     - `costBest` (best cost)\n",
    "\n",
    "4. **Store iteration data**  \n",
    "   - Save the iteration number, current solution, best solution, current cost, and best cost in the matrix.\n",
    "\n",
    "**Step 4: Repeat for a Fixed Number of Iterations**\n",
    "- Continue the process until reaching the maximum number of iterations (`max_iterations`).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae696518-5d04-4598-bea4-f3abb4e519e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GS(s_initial, max_iterations, cost_function, print_info=True):\n",
    "    \"\"\"\n",
    "    Implements the Greedy Stochastic (GS) optimization algorithm.\n",
    "\n",
    "    In this algorithm, the next value of 's' is randomly selected from \n",
    "    the neighbors of the best solution found so far. This introduces some \n",
    "    exploration while still favoring local improvement.\n",
    "\n",
    "    Parameters:\n",
    "        s_initial (int): The initial value of s.\n",
    "        max_iterations (int): The maximum number of iterations to run the algorithm.\n",
    "        cost_function (function): A function that computes the cost given an input s.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A matrix storing iteration number, current s, best s, \n",
    "                    current cost, and best cost for all iterations.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the current solution and its cost\n",
    "\n",
    "    \n",
    "\n",
    "    # Initialize the best solution and its cost\n",
    "\n",
    "    \n",
    "\n",
    "    # Create a matrix to store results (iteration, current s, best s, current cost, best cost)\n",
    "\n",
    "    \n",
    "    # Store initial values in the matrix\n",
    "\n",
    "    \n",
    "    # Loop through the maximum number of iterations\n",
    "    for i in range(1, max_iterations):\n",
    "        # Select a new solution randomly from the neighbors of the best solution found so far\n",
    "\n",
    "        \n",
    "        # Compute the cost of the new solution\n",
    "\n",
    "        \n",
    "        # If the new solution improves upon the best found so far, update best values\n",
    "        if costCurrent < costBest:\n",
    "\n",
    "            \n",
    "\n",
    "        # Store the results for this i\n",
    "\n",
    "        \n",
    "    if print_info:\n",
    "        print(\"Final i:\", int(i))\n",
    "        print(f\"Best Solution Found: {int(sBest)} with Cost: {costBest:.4f}\")\n",
    "        print(f\"Final Current Solution: {int(sCurrent)} with Cost: {costCurrent:.4f}\")\n",
    "    \n",
    "    # Return the matrix containing the results of all i\n",
    "    return results_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2189961-cf65-4fa9-9561-33c4e3f7c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['GS'][0] = GS(initial_point, maxIter, cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec9c184-36e2-4f04-9900-4bce9c814f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_run(result, 'GS', maxIter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a435c-6232-419b-94f5-e9acd5d15e32",
   "metadata": {},
   "source": [
    "- Compare the Evolution of the Cost Functional for the 4 algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd67b95-080d-4eed-8f1f-225ba1dd7195",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result['RW'][0,:,0], np.average(result['RW'][:,:,4], axis=0), label='RW')\n",
    "plt.plot(result['RS'][0,:,0], np.average(result['RS'][:,:,4], axis=0), label='RS')\n",
    "plt.plot(result['GD'][0,:,0], np.average(result['GD'][:,:,4], axis=0), label='GD')\n",
    "plt.plot(result['GS'][0,:,0], np.average(result['GS'][:,:,4], axis=0), label='GS')\n",
    "pretty_plot_gs(xlim=(0,maxIter), xlabel='Iteration', ylabel='costBest', title='Comparison of the 4 Algorithms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a282be-e11c-43e9-91f4-6fab1da390aa",
   "metadata": {},
   "source": [
    "- We now run all the algorithms several times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01783e2c-5df6-4e7f-bca8-50123bddae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_many = 30\n",
    "maxIter_many = 2000\n",
    "results_many = {'RW':np.empty((times_many, maxIter_many, 5)) , 'RS':np.empty((times_many, maxIter_many, 5)), 'GD':np.empty((times_many, maxIter_many, 5)), 'GS':np.empty((times_many, maxIter_many, 5))}\n",
    "initial_point_many = 100\n",
    "for i in range(times_many):\n",
    "    results_many['RW'][i] = RW(initial_point_many, maxIter_many, cost, print_info=False)\n",
    "    results_many['RS'][i] = RS(initial_point_many, maxIter_many, cost, print_info=False)\n",
    "    results_many['GD'][i] = GD(initial_point_many, maxIter_many, cost, print_info=False)\n",
    "    results_many['GS'][i] = GS(initial_point_many, maxIter_many, cost, print_info=False)\n",
    "\n",
    "    \n",
    "# Print the average minimum number for all methods.\n",
    "ave_rw = np.average(results_many['RW'][:, :, 2])\n",
    "ave_rs = np.average(results_many['RS'][:, :, 2])\n",
    "ave_gd = np.average(results_many['GD'][:, :, 2])\n",
    "ave_gs = np.average(results_many['GS'][:, :, 2])\n",
    "\n",
    "print(f\"Average of sBest for Random Walk:          {ave_rw:.4f}\")\n",
    "print(f\"Average of sBest for Random Sampling:      {ave_rs:.4f}\")\n",
    "print(f\"Average of sBest for Greedy Deterministic: {ave_gd:.4f}\")\n",
    "print(f\"Average of sBest for Greedy Search:        {ave_gs:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48962b8-7888-48f7-87e9-a5d360380f9d",
   "metadata": {},
   "source": [
    "- We plot the average of the evolution of the Cost Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e3bdf4-064f-4990-9a97-7a0d19a8a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results_many['RW'][0,:,0], np.average(results_many['RW'][:,:,4], axis=0), label='RW')\n",
    "plt.plot(results_many['RS'][0,:,0], np.average(results_many['RS'][:,:,4], axis=0), label='RS')\n",
    "plt.plot(results_many['GD'][0,:,0], np.average(results_many['GD'][:,:,4], axis=0), label='GD')\n",
    "plt.plot(results_many['GS'][0,:,0], np.average(results_many['GS'][:,:,4], axis=0), label='GS')\n",
    "pretty_plot_gs(xlim=(0,maxIter), xlabel='Iteration', ylabel='costBest', title='Comparison of the 4 Algorithms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ece097-915d-45a2-8949-f5b5f47f0fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''AT THE 100th ITERATION\n",
    "\\tAvg.\\tSD\n",
    "RW\\t{:.0f}\\t{:.0f}\n",
    "RS\\t{:.0f}\\t{:.0f}\n",
    "GD\\t{:.0f}\\t{:.0f}\n",
    "GS\\t{:.0f}\\t{:.0f}'''.format(np.average(results_many['RW'][:,100,4]), np.std(results_many['RW'][:,100,4]),\n",
    "    np.average(results_many['RS'][:,100,4]), np.std(results_many['RS'][:,100,4]),\n",
    "    np.average(results_many['GD'][:,100,4]), np.std(results_many['GD'][:,100,4]),\n",
    "    np.average(results_many['GS'][:,100,4]), np.std(results_many['GS'][:,100,4])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
